<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>title</title>
    <script type="module">

      import shaderCreator from "./js/shaders.js";
      import { default as init, VelloEncoding } from "./pkg/vello_js.js";

      init().then( async () => {
        const width = 512;
        const height = 512;

        const adapter = await navigator.gpu?.requestAdapter();
        const device = await adapter?.requestDevice( {
            requiredFeatures: [ 'bgra8unorm-storage' ]
        } );
        if ( !device ) {
          throw new Error( 'need a browser that supports WebGPU' );
        }

        device.lost.then( info => {
          console.error( `WebGPU device was lost: ${info.message}` );

          // 'reason' will be 'destroyed' if we intentionally destroy the device.
          if ( info.reason !== 'destroyed' ) {
            // TODO: handle destruction
          }
        } );

        const preferredFormat = navigator.gpu.getPreferredCanvasFormat();
        const actualFormat = 'rgba8unorm';

        const shaders = shaderCreator( preferredFormat );
        window.shaders = shaders;

        const canvas = document.createElement( 'canvas' );
        canvas.width = width;
        canvas.height = height;


        document.body.appendChild( canvas );

        const context = canvas.getContext( 'webgpu' );
        context.configure( {
          device,
          format: preferredFormat,
          usage: GPUTextureUsage.COPY_SRC | GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.STORAGE_BINDING
        } );

        // Handle high-dpi
        const backingScale = window.devicePixelRatio;
        canvas.style.width = `${Math.floor( width / backingScale )}px`;
        canvas.style.height = `${Math.floor( height / backingScale )}px`;

        const encoding = new VelloEncoding();
        encoding.reset( false );
        const angle = 0.3;
        let c = Math.cos( angle );
        let s = Math.sin( angle );

        encoding.matrix( c, s, -s, c, 200, 100 );
        encoding.json_path( true, true, JSON.stringify( [
          { type: 'MoveTo', x: -100, y: -100 },
          { type: 'QuadTo', x1: 0, y1: 0, x2: 100, y2: -100 },
          // { type: 'LineTo', x: 100, y: -100 },
          { type: 'LineTo', x: 100, y: 100 },
          { type: 'CubicTo', x1: 0, y1: 200, x2: 0, y2: 0, x3: -100, y3: 100 },
          // { type: 'LineTo', x: -100, y: 100 },
          { type: 'LineTo', x: -100, y: -100 }
        ] ) );
        encoding.color( 0xffffffff );

        encoding.matrix( c, s, -s, c, 200, 300 );
        encoding.json_path( true, true, JSON.stringify( [
          { type: 'MoveTo', x: -100, y: -100 },
          { type: 'LineTo', x: 100, y: -100 },
          { type: 'LineTo', x: 300, y: 100 },
          { type: 'LineTo', x: -100, y: 100 },
          { type: 'LineTo', x: -100, y: -100 }
        ] ) );
        encoding.color( 0xff0000ff );

        // TODO: why is the third one not showing up? Seems like it only shows up if we execute another dummy path
        encoding.matrix( c, s, -s, c, 200, 400 );
        encoding.json_path( true, true, JSON.stringify( [
          { type: 'MoveTo', x: -100, y: -100 },
          { type: 'LineTo', x: 100, y: -100 },
          { type: 'LineTo', x: 0, y: 100 },
          { type: 'LineTo', x: -100, y: 100 },
          { type: 'LineTo', x: -100, y: -100 }
        ] ) );
        encoding.color( 0x00ff00ff );

        const renderInfo = encoding.render( width, height, 0x000066ff );

        Object.keys( shaders ).forEach( shaderName => {
          const shader = shaders[ shaderName ];
          shader.module = device.createShaderModule( {
            label: shaderName,
            code: shader.wgsl
          } );

          shader.bindGroupLayout = device.createBindGroupLayout( {
            label: `${shaderName} bindGroupLayout`,
            entries: shader.bindings.map( ( binding, i ) => {
              const entry = {
                binding: i,
                visibility: GPUShaderStage.COMPUTE,
              };

              if ( binding === 'Buffer' || binding === 'BufReadOnly' || binding === 'Uniform' ) {
                entry.buffer = {
                  type: {
                    Buffer: 'storage',
                    BufReadOnly: 'read-only-storage',
                    Uniform: 'uniform'
                  }[ binding ],
                  hasDynamicOffset: false
                };
              }
              else if ( binding === 'Image' ) {
                entry.storageTexture = {
                  access: 'write-only',
                  // format: preferredFormat,
                  // format: actualFormat, // We actually probably need rgba8 for the shaders to work, oops
                  format: preferredFormat, // We actually probably need rgba8 for the shaders to work, oops
                  viewDimension: '2d'
                };
              }
              else if ( binding === 'ImageRead' ) {
                // Note: fine takes ImageFormat::Rgba8 for Image/ImageRead
                entry.texture = {
                  sampleType: 'float',
                  viewDimension: '2d',
                  multisampled: false
                };
              }
              else {
                throw new Error( `unknown binding: ${binding}` );
              }

              return entry;
            } )
          } );

          shader.pipeline = device.createComputePipeline( {
            label: `${shaderName} pipeline`,
            layout: device.createPipelineLayout( {
              bindGroupLayouts: [ shader.bindGroupLayout ],
            } ),
            compute: {
              module: shader.module,
              entryPoint: 'main',
            },
          } );
        } );

        const sceneBytes = renderInfo.scene();
        const layout = renderInfo.layout();
        const configUniform = renderInfo.config_uniform();
        const workgroupCounts = renderInfo.workgroup_counts();
        const bufferSizes = renderInfo.buffer_sizes();
        const configBytes = renderInfo.config_bytes();
        console.log( `use_large_path_scan: ${workgroupCounts.use_large_path_scan}` );

        // TODO: gradients/images here

        // TODO: We'll need a solution to pool buffers
        const createBuffer = ( label, size ) => {
          const buffer = device.createBuffer( {
            label,
            size: Math.max( size, 16 ), // Min of 16 bytes used, copying vello buffer requirements
            usage: GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST | GPUBufferUsage.STORAGE
          } );
          return buffer;
        };

        const sceneBuffer = createBuffer( 'scene buffer', sceneBytes.byteLength );
        device.queue.writeBuffer( sceneBuffer, 0, sceneBytes.buffer );

        const configBuffer = device.createBuffer( {
          label: 'config buffer',
          size: configBytes.byteLength,
          // Different than the typical buffer
          usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
        } );
        device.queue.writeBuffer( configBuffer, 0, configBytes.buffer );

        const infoBinDataBuffer = createBuffer( 'info_bin_data buffer', bufferSizes.bin_data.size_in_bytes );
        const tileBuffer = createBuffer( 'tile buffer', bufferSizes.tiles.size_in_bytes );
        const segmentsBuffer = createBuffer( 'segments buffer', bufferSizes.segments.size_in_bytes );
        const ptclBuffer = createBuffer( 'ptcl buffer', bufferSizes.ptcl.size_in_bytes );
        const reducedBuffer = createBuffer( 'reduced buffer', bufferSizes.path_reduced.size_in_bytes );

        // TODO: rename, buffer could be GPUTextureView also
        const buffersToEntries = buffers => buffers.map( ( buffer, i ) => ( {
          binding: i,
          // handle GPUTextureView
          resource: buffer instanceof GPUBuffer ? { buffer: buffer } : buffer
        } ) );

        const encoder = device.createCommandEncoder( {
          label: 'the encoder',
        } );

        const dispatch = ( shaderName, internalShaderName, wg_counts, buffers ) => {
          const shader = shaders[ internalShaderName ];
          const bindGroup = device.createBindGroup( {
            label: `${shaderName} bindGroup`,
            layout: shader.bindGroupLayout,
            entries: buffersToEntries( buffers )
          } );
          const computePass = encoder.beginComputePass( {
            label: `${shaderName} compute pass`
          } );
          computePass.setPipeline( shader.pipeline );
          computePass.setBindGroup( 0, bindGroup );
          computePass.dispatchWorkgroups( wg_counts.x, wg_counts.y, wg_counts.z );
          computePass.end(); // TODO: does this mess stuff up?
        };

        dispatch( 'pathtag_reduce', 'pathtag_reduce', workgroupCounts.path_reduce, [ configBuffer, sceneBuffer, reducedBuffer ] );

        let pathtag_parent = reducedBuffer;
        let large_pathtag_bufs = null;

        if ( workgroupCounts.use_large_path_scan ) {
          const reduced2Buffer = createBuffer( 'reduced2 buffer', bufferSizes.path_reduced2.size_in_bytes );

          dispatch( 'pathtag_reduce2', 'pathtag_reduce2', workgroupCounts.path_reduce2, [ reducedBuffer, reduced2Buffer ] );

          const reducedScanBuffer = createBuffer( 'reducedScan buffer', bufferSizes.path_reduced_scan.size_in_bytes );

          dispatch( 'pathtag_scan1', 'pathtag_scan1', workgroupCounts.path_scan1, [ reducedBuffer, reduced2Buffer, reducedScanBuffer ] );

          pathtag_parent = reducedScanBuffer;
          large_pathtag_bufs = [ reduced2Buffer, reducedScanBuffer ];
        }

        const tagmonoidBuffer = createBuffer( 'tagmonoid buffer', bufferSizes.path_monoids.size_in_bytes );

        // TODO: running the right shader?
        if ( workgroupCounts.use_large_path_scan ) {
          dispatch( 'pathtag_scan', 'pathtag_scan_large', workgroupCounts.path_scan, [ configBuffer, sceneBuffer, pathtag_parent, tagmonoidBuffer ] );
        }
        else {
          dispatch( 'pathtag_scan', 'pathtag_scan_small', workgroupCounts.path_scan, [ configBuffer, sceneBuffer, pathtag_parent, tagmonoidBuffer ] );
        }

        // free reducedBuffer
        // if ( large_pathtag_bufs ) {
        //   // free reduced2 / reducedScan
        // }

        const pathBBoxBuffer = createBuffer( 'pathBBox buffer', bufferSizes.path_bboxes.size_in_bytes );
        dispatch( 'bbox_clear', 'bbox_clear', workgroupCounts.bbox_clear, [ configBuffer, pathBBoxBuffer ] );

        const cubicBuffer = createBuffer( 'cubic buffer', bufferSizes.cubics.size_in_bytes );

        dispatch( 'pathseg', 'pathseg', workgroupCounts.path_seg, [ configBuffer, sceneBuffer, tagmonoidBuffer, pathBBoxBuffer, cubicBuffer ] );

        const drawReducedBuffer = createBuffer( 'drawReduced buffer', bufferSizes.draw_reduced.size_in_bytes );

        dispatch( 'draw_reduce', 'draw_reduce', workgroupCounts.draw_reduce, [ configBuffer, sceneBuffer, drawReducedBuffer ] );

        const drawMonoidBuffer = createBuffer( 'drawMonoid buffer', bufferSizes.draw_monoids.size_in_bytes );
        const clipInpBuffer = createBuffer( 'clipInp buffer', bufferSizes.clip_inps.size_in_bytes );

        dispatch( 'draw_leaf', 'draw_leaf', workgroupCounts.draw_leaf, [ configBuffer, sceneBuffer, drawReducedBuffer, pathBBoxBuffer, drawMonoidBuffer, infoBinDataBuffer, clipInpBuffer ] );

        // free drawReducedBuffer

        const clipElBuffer = createBuffer( 'clipEl buffer', bufferSizes.clip_els.size_in_bytes );
        const clipBicBuffer = createBuffer( 'clipBic buffer', bufferSizes.clip_bics.size_in_bytes );

        if ( workgroupCounts.clip_reduce.x > 0 ) {
          dispatch( 'clip_reduce', 'clip_reduce', workgroupCounts.clip_reduce, [ configBuffer, clipInpBuffer, pathBBoxBuffer, clipBicBuffer, clipElBuffer ] );
        }

        const clipBBoxBuffer = createBuffer( 'clipBBox buffer', bufferSizes.clip_bboxes.size_in_bytes );

        if ( workgroupCounts.clip_leaf.x > 0 ) {
          dispatch( 'clip_leaf', 'clip_leaf', workgroupCounts.clip_leaf, [ configBuffer, clipInpBuffer, pathBBoxBuffer, clipBicBuffer, clipElBuffer, drawMonoidBuffer, clipBBoxBuffer ] );
        }

        // free clipInpBuffer, clipBicBuffer, clipElBuffer

        const drawBBoxBuffer = createBuffer( 'drawBBox buffer', bufferSizes.draw_bboxes.size_in_bytes );
        const bumpBuffer = createBuffer( 'bump buffer', bufferSizes.bump_alloc.size_in_bytes );
        const binHeaderBuffer = createBuffer( 'binHeader buffer', bufferSizes.bin_headers.size_in_bytes );

        // TODO: wgpu might not have this implemented? Do I need a manual clear?
        // TODO: actually, we're not reusing the buffer, so it might be zero'ed out? Check spec
        // TODO: See if this clearBuffer is insufficient (implied by engine.rs docs)
        encoder.clearBuffer( bumpBuffer, 0 );
        // device.queue.writeBuffer( bumpBuffer, 0, new Uint8Array( bumpBuffer.size ) );

        dispatch( 'binning', 'binning', workgroupCounts.binning, [ configBuffer, drawMonoidBuffer, pathBBoxBuffer, clipBBoxBuffer, drawBBoxBuffer, bumpBuffer, infoBinDataBuffer, binHeaderBuffer ] );

        // free drawMonoidBuffer, pathBBoxBuffer, clipBBoxBuffer

        // Note: this only needs to be rounded up because of the workaround to store the tile_offset
        // in storage rather than workgroup memory.
        const pathBuffer = createBuffer( 'path buffer', bufferSizes.paths.size_in_bytes );

        dispatch( 'tile_alloc', 'tile_alloc', workgroupCounts.tile_alloc, [ configBuffer, sceneBuffer, drawBBoxBuffer, bumpBuffer, pathBuffer, tileBuffer ] );

        // free drawBBoxBuffer

        dispatch( 'path_coarse', 'path_coarse_full', workgroupCounts.path_coarse, [ configBuffer, sceneBuffer, tagmonoidBuffer, cubicBuffer, pathBuffer, bumpBuffer, tileBuffer, segmentsBuffer ] );

        // free tagmonoidBuffer, cubicBuffer

        dispatch( 'backdrop', 'backdrop_dyn', workgroupCounts.backdrop, [ configBuffer, pathBuffer, tileBuffer ] );

        dispatch( 'coarse', 'coarse', workgroupCounts.coarse, [ configBuffer, sceneBuffer, drawMonoidBuffer, binHeaderBuffer, infoBinDataBuffer, pathBuffer, tileBuffer, bumpBuffer, ptclBuffer ] );

        // free sceneBuffer, drawMonoidBuffer, binHeaderBuffer, pathBuffer

        // let out_image = ImageProxy::new(params.width, params.height, ImageFormat::Rgba8);
        //
        // // NOTE: not apparently using robust for wasm?
            // Note: in the wasm case, we're currently not running the robust
            // pipeline, as it requires more async wiring for the readback.
        // if robust {
        //     recording.download(*bump_buf.as_buf().unwrap());
        // }

        const outImage = device.createTexture( {
          label: 'outImage',
          size: {
            width: width,
            height: height,
            depthOrArrayLayers: 1
          },
          format: actualFormat,
          // TODO: wtf, usage: TextureUsages::TEXTURE_BINDING | TextureUsages::COPY_DST,
          usage: GPUTextureUsage.COPY_SRC | GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.STORAGE_BINDING
        } );
        const outImageView = outImage.createView( {
          label: 'outImageView',
          format: actualFormat,
          dimension: '2d'
        } );

        const gradientImage = device.createTexture( {
          label: 'gradientImage',
          size: {
            width: 1, // TODO: actual
            height: 1, // TODO: actual
            depthOrArrayLayers: 1
          },
          format: actualFormat,
          usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST
        } );
        const gradientImageView = gradientImage.createView( {
          label: 'gradientImageView',
          format: actualFormat,
          dimension: '2d'
        } );

        const atlasImage = device.createTexture( {
          label: 'atlasImage',
          size: {
            width: 1, // TODO: actual
            height: 1, // TODO: actual
            depthOrArrayLayers: 1
          },
          format: actualFormat,
          usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST
        } );
        const atlasImageView = atlasImage.createView( {
          label: 'atlasImageView',
          format: actualFormat,
          dimension: '2d'
        } );

        const canvasOutView = context.getCurrentTexture().createView();

        // dispatch( 'fine', 'fine', workgroupCounts.fine, [ configBuffer, tileBuffer, segmentsBuffer, outImageView, ptclBuffer, gradientImageView, infoBinDataBuffer, atlasImageView ] );
        dispatch( 'fine', 'fine', workgroupCounts.fine, [ configBuffer, tileBuffer, segmentsBuffer, canvasOutView, ptclBuffer, gradientImageView, infoBinDataBuffer, atlasImageView ] );

        // NOTE: bgra8unorm vs rgba8unorm can't be copied, so this depends on the platform?
        // encoder.copyTextureToTexture( {
        //   texture: outImage
        // }, {
        //   texture: context.getCurrentTexture()
        // }, {
        //   width: width,
        //   height: height,
        //   depthOrArrayLayers: 1
        // } );

        /* NOTES: bits of coarse/fine shader calls not moved over, including buffer frees
        self.fine_wg_count = Some(wg_counts.fine);
        self.fine_resources = Some(FineResources {
            config_buf,
            bump_buf,
            tile_buf,
            segments_buf,
            ptcl_buf,
            gradient_image,
            info_bin_data_buf,
            image_atlas: ResourceProxy::Image(image_atlas),
            out_image,
        });
        recording.free_resource(bump_buf);
        recording

        ......

        let fine_wg_count = self.fine_wg_count.take().unwrap();
        let fine = self.fine_resources.take().unwrap();
        recording.dispatch(
            shaders.fine,
            fine_wg_count,
            [
                fine.config_buf,
                fine.tile_buf,
                fine.segments_buf,
                ResourceProxy::Image(fine.out_image),
                fine.ptcl_buf,
                fine.gradient_image,
                fine.info_bin_data_buf,
                fine.image_atlas,
            ],
        );
        recording.free_resource(fine.config_buf);
        recording.free_resource(fine.tile_buf);
        recording.free_resource(fine.segments_buf);
        recording.free_resource(fine.ptcl_buf);
        recording.free_resource(fine.gradient_image);
        recording.free_resource(fine.image_atlas);
        recording.free_resource(fine.info_bin_data_buf);
         */

        const commandBuffer = encoder.finish();
        device.queue.submit( [ commandBuffer ] );
      });

      // NOTE: Some render-path notes below:
      // render_to_surface
      // render_to_surface_async
      // Event::RedrawRequested (in with_winit's src/lib)
      // render_to_surface / render_to_surface_async
      // render_to_texture_async ( or... render_encoding_full )
      // render_encoding_coarse / record_fine

    </script>
  </head>
  <body>
  </body>
</html>